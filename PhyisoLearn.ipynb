{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- [mne.io.RawArray.plot](https://mne.tools/stable/generated/mne.io.RawArray.html#mne.io.RawArray.plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Test 1:\n",
    "\n",
    "```python\n",
    "window_sizes = [2.0]\n",
    "overlaps = [0.1]\n",
    "accuracy ~90%\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'brainflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1be056f11654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbrainflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_filter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFilterTypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAggOperations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'brainflow'"
     ]
    }
   ],
   "source": [
    "from brainflow.data_filter import DataFilter, FilterTypes, AggOperations\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import copy\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "class PhysioLearn:\n",
    "    def __init__(self, sessionTitle, num_channels, channel_type, eventMapping=None, eventFile=None, ):\n",
    "        print()\n",
    "        self.currentFileDf = []\n",
    "        self.currentFile = None\n",
    "        self.channels = num_channels\n",
    "        self.channelTypes = [channel_type] * num_channels\n",
    "        self.channelNames = [str(n) for n in range(num_channels)]\n",
    "        self.sfreq = 200\n",
    "        self.mneFactor = 1000000 # account for unit conversion if necessary\n",
    "        self.markerChannel = 14\n",
    "        self.eventMapping = eventMapping\n",
    "        \n",
    "        # Check if this is the best approach\n",
    "        if eventFile != None:\n",
    "            self.events = mne.read_events(eventFile)\n",
    "        else:\n",
    "            self.events = []\n",
    "            \n",
    "        self.date = datetime.now().strftime(\"%H_%M_%S\")\n",
    "        self.eventsEmbeded = []\n",
    "        self.raw = None\n",
    "        self.dataset = []\n",
    "        self.info = mne.create_info(\n",
    "            ch_names=self.channelNames, sfreq=self.sfreq, ch_types=self.channelTypes)\n",
    "        print(\"Init Success\")\n",
    "\n",
    "    def createEvents(self, filePath):\n",
    "        i = 0\n",
    "        array = []\n",
    "        for sample in self.currentFileDf[self.markerChannel]:\n",
    "            i = i + 1\n",
    "            if sample != 0.0:\n",
    "                array.append([i, 0, int(sample)])\n",
    "        self.eventsEmbeded = np.array(array, dtype=int)\n",
    "        df = pd.DataFrame(data=self.eventsEmbeded).to_csv(filePath, sep=\" \", index=None, header=None)\n",
    "\n",
    "        \n",
    "\n",
    "    def readFile(self, location):\n",
    "        self.currentFile = DataFilter.read_file(location)\n",
    "        self.currentFileDf = pd.DataFrame(np.transpose(self.currentFile))\n",
    "        res = self.currentFile[1:2] / self.mneFactor # only accounts for 1 channel currently\n",
    "        self.raw = mne.io.RawArray(res, self.info)\n",
    "        \n",
    "\n",
    "    def getDataDuration(self):\n",
    "        #seconds\n",
    "        return len(self.currentFile[0]) / self.sfreq\n",
    "         \n",
    "    def createPlots(self): # what is this doing? \n",
    "        duration = round(self.getDataDuration() - 2)\n",
    "        window_size = duration / 4\n",
    "        if len(self.eventsEmbeded) == 0:\n",
    "            events = self.events\n",
    "        else:\n",
    "            events = self.eventsEmbeded\n",
    "        for i in range(4):\n",
    "            start = i * window_size\n",
    "            self.raw.plot(events=events, start=start, duration=window_size,\n",
    "                 event_id=self.eventMapping)\n",
    "            \n",
    "    def getEvents(self):\n",
    "        if len(self.eventsEmbeded) == 0:\n",
    "            events = self.events\n",
    "        else:\n",
    "            events = self.eventsEmbeded\n",
    "        \n",
    "        return events\n",
    "    \n",
    "    def getWindowBandPower(self, start, duration):\n",
    "        epoch, times = self.getEpoch(start, duration)\n",
    "        [avgs, stddevs] = DataFilter.get_avg_band_powers(epoch, [0], self.sfreq, True)\n",
    "        print(avgs)\n",
    "        return avgs\n",
    "        \n",
    "    def plotEvents(self, eventDuration):\n",
    "        events = self.getEvents()\n",
    "        e_map = {100: 'Rest', 99: 'Lift', 98: 'Squeeze' }\n",
    "        for event in events:\n",
    "            data, times = self.getEpoch(int(event[0] / self.sfreq), eventDuration)\n",
    "            fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "            title = e_map[event[2]]\n",
    "            plt.title(title)\n",
    "            ax.plot(times, data[0] * self.mneFactor)\n",
    "            #plt.savefig('raw.png')\n",
    "            \n",
    "    def plot(self, title, data, times):\n",
    "        fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "        plt.title(title)\n",
    "        ax.plot(times, data * self.mneFactor)\n",
    "        \n",
    "            \n",
    "    def featureExtraction(self, window_sizes, overlaps):\n",
    "        events = self.getEvents()\n",
    "        e_map = {100: 'Rest', 99: 'Lift', 98: 'Squeeze' }\n",
    "        window_sizes = window_sizes\n",
    "        channels = [0]\n",
    "        overlaps = overlaps\n",
    "        dataset_x = list()\n",
    "        dataset_y = list()\n",
    "        epochSize = 4\n",
    "        \n",
    "        \n",
    "        for event in events:\n",
    "            for num, window_size in enumerate(window_sizes):\n",
    "                    data, times = self.getEpoch(int(event[0] / self.sfreq), epochSize)\n",
    "                    cur_pos = 0\n",
    "                    while cur_pos + int(window_size * self.sfreq) < data.shape[1]:\n",
    "                        _class = event[2]\n",
    "                        data_in_window = data[:, cur_pos:cur_pos + int(window_size * self.sfreq)]\n",
    "                        times_in_window = times[cur_pos:cur_pos + int(window_size * self.sfreq)]\n",
    "                        #print(data.shape, times.shape)\n",
    "                        #plotTitle = f'{cur_pos}_{_class}_window({window_size})'\n",
    "                        #dataCopy = copy.deepcopy(data_in_window[0])\n",
    "                        #DataFilter.perform_lowpass(data_in_window[0], self.sfreq, 30.0, 1,\n",
    "                        #          FilterTypes.BUTTERWORTH.value, 1)\n",
    "                        #self.plot(plotTitle, data_in_window[0], times_in_window)\n",
    "                        #self.plot(plotTitle+\"filtered\", dataCopy, times_in_window)\n",
    "                        \n",
    "                        # returns 2d array with delta - gamma (bands[0]) \n",
    "                        bands = DataFilter.get_avg_band_powers(data_in_window, channels, self.sfreq, True)\n",
    "                        feature_vector = bands[0]\n",
    "                        if (event[2] != 98):\n",
    "                            dataset_x.append(feature_vector)\n",
    "                            dataset_y.append(e_map[_class])\n",
    "                        \n",
    "                        # review overlap to make it more intuitive....\n",
    "                        cur_pos = cur_pos + int(window_size * overlaps[num] * self.sfreq)\n",
    "        self.dataset = [dataset_x, dataset_y]\n",
    "        return dataset_x, dataset_y\n",
    "                 \n",
    "    def getEpoch(self, start, eventDuration):\n",
    "        start = start * self.sfreq\n",
    "        duration = eventDuration * self.sfreq\n",
    "        stop = start + duration\n",
    "        data, times = self.raw.get_data(return_times=True, start=start, stop=stop)\n",
    "        return data, times\n",
    "    \n",
    "    def saveObject(self, model, filename): \n",
    "        joblib.dump(model, filename)\n",
    "        \n",
    "    def loadObject(self, fileName):\n",
    "        model = joblib.load(fileName)\n",
    "        return model\n",
    "    \n",
    "    def testLocalModel(self, modelFileName, dataset, test_size=0.33, random_state=1):\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(dataset[0], dataset[1], test_size=test_size, random_state=random_state)\n",
    "        model = self.loadModel(modelFileName)\n",
    "        score = model.score(X_test, Y_test)\n",
    "        x = self.dataset[0]\n",
    "        predicted = model.predict(x)\n",
    "        return score\n",
    "        \n",
    "\n",
    "    def start(self, fileName):\n",
    "        self.readFile(fileName)\n",
    "        #self.createEvents()\n",
    "        #self.createPlots() \n",
    "        #self.plotEvents(4)\n",
    "        #data, times = self.getEpoch(0, 10)\n",
    "        #self.getWindowBandPower(0, 5)\n",
    "        \n",
    "        # Get Dataset\n",
    "        #self.dataset = self.prepareData([2.0], [0.1]) # get dataset\n",
    "        \n",
    "        # Train Model\n",
    "        #self.train_knn(self.dataset, 1)\n",
    "        #self.train_lda(self.dataset)\n",
    "        #self.train_regression(self.dataset)\n",
    "        \n",
    "        # Test model\n",
    "        #score = self.testLocalModel(\"models/lda-emg-lift.pkl\", self.dataset)\n",
    "        \n",
    "        #self.saveObject(self.dataset, \"models/squeeze-emg-x-y.dataset\")\n",
    "        \n",
    "        # Load Model\n",
    "        #data = self.loadObject(\"models/lift-emg-x-y.dataset\")\n",
    "     \n",
    "        \n",
    "    ''' Training '''\n",
    "    def train_knn(self, data, neighbors):\n",
    "        print('#### KNN ####')\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='f1_macro', n_jobs=8)\n",
    "        print('f1 macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='precision_macro', n_jobs=8)\n",
    "        print('precision macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='recall_macro', n_jobs=8)\n",
    "        print('recall macro %s' % str(scores.mean()))\n",
    "        \n",
    "    def train_regression(self, data):\n",
    "        print('#### Logistic Regression ####')\n",
    "        model = LogisticRegression(class_weight='balanced', solver='liblinear',\n",
    "                               max_iter=4000, penalty='l2', random_state=1)\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='f1_macro', n_jobs=8)\n",
    "        print('f1 macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='precision_macro', n_jobs=8)\n",
    "        print('precision macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='recall_macro', n_jobs=8)\n",
    "        print('recall macro %s' % str(scores.mean()))\n",
    "        \n",
    "    \n",
    "    def train_lda(self, data):\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "        print('#### Linear Discriminant Analysis ####')\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='f1_macro', n_jobs=8)\n",
    "        print('f1 macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='precision_macro', n_jobs=8)\n",
    "        print('precision macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='recall_macro', n_jobs=8)\n",
    "        print('recall macro %s' % str(scores.mean()))\n",
    "        model.fit(data[0], data[1])\n",
    "        #self.saveObject(model, \"models/lda-emg-lift.pkl\")\n",
    "        \n",
    "        \n",
    "def main():  \n",
    "    event_mapping = {'Rest': 100, 'Lift': 99, 'Squeeze': 98}\n",
    "    #learn = PhysioLearn(1, \"emg\", event_mapping, \"data/events-gen-cleaned-eve.txt\")\n",
    "    learn = PhysioLearn(\"Crawford_EMG_Model\", 1, \"emg\", event_mapping)\n",
    "    learn.readFile(\"data/trial1.csv\")\n",
    "    learn.createEvents(\"data/crawfordTEST_events.txt\")\n",
    "    learn.plotEvents(2)\n",
    "    dataset = learn.featureExtraction([2.0], [0.1])\n",
    "    \n",
    "    # Train Model\n",
    "    learn.train_knn(dataset, 1)\n",
    "    learn.train_lda(dataset)\n",
    "    learn.train_regression(dataset)\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
